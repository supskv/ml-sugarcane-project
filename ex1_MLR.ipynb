{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2cc4bd1-50f0-47f1-9df5-78906c65e16b",
   "metadata": {},
   "source": [
    "# Level 1 - Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f37518a-83bb-4089-b4a7-dfcf966c6ecb",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cc731f2-2f23-40fc-84c0-d1fb92ab7417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# from google.colab import drive\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f877fd-ceb5-4f0b-8e2d-704facc8c8a2",
   "metadata": {},
   "source": [
    "## 2. Data Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8519946-6fb8-4f0a-beaf-2076c568b43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_data(filename):\n",
    "    \n",
    "    # read file\n",
    "    raw = pd.read_csv(filename)\n",
    "    \n",
    "    # define columns to be extracted\n",
    "    ndvi_col = ['ndvi_mean'+str(i) for i in range(1, 24+1)] # ndvi_mean1, ..., ndvi_mean24\n",
    "    savi_col = ['ndvi_mean'+str(i) for i in range(1, 24+1)] # ndvi_mean1, ..., savi_mean24\n",
    "    evi_col = ['ndvi_mean'+str(i) for i in range(1, 24+1)] # ndvi_mean1, ..., evi_mean24\n",
    "\n",
    "    # extract each feature\n",
    "    ndvi_timeseries = raw[ndvi_col]\n",
    "    savi_timeseries = raw[savi_col]\n",
    "    evi_timeseries = raw[evi_col]\n",
    "    \n",
    "    # dimension stack\n",
    "    data = np.dstack([ndvi_timeseries, savi_timeseries, evi_timeseries])\n",
    "    \n",
    "    # get only label\n",
    "    label = raw.iloc[:, -1]\n",
    "    \n",
    "    return data, label\n",
    "\n",
    "def data_to_lv1_x_y(data, labels):\n",
    "    \n",
    "    # export all X\n",
    "    # but reclass the plant cane -> 100, ratoon cane -> 200\n",
    "    target = copy(labels)\n",
    "    target[target > 200] = 200\n",
    "    target[(target < 200) & (target > 100)] = 100\n",
    "    \n",
    "    return data, target\n",
    "\n",
    "def data_to_lv2_x_y(data, target):\n",
    "    \n",
    "    # export X plant which labels are 100-200\n",
    "    X_plant = data[(target > 100) & (target <200)]\n",
    "    \n",
    "    # export X ratoon which labels are >200\n",
    "    X_ratoon = data[target > 200]\n",
    "    \n",
    "    # export y plant which labels are 100-200\n",
    "    y_plant = target[(target > 100) & (target < 200)]\n",
    "    \n",
    "    # export y ratoon which labels are >200\n",
    "    y_ratoon = target[target > 200]\n",
    "    \n",
    "    return X_plant, y_plant, X_ratoon, y_ratoon\n",
    "\n",
    "def label_encode(y):\n",
    "    \n",
    "    target = copy(y)\n",
    "    # redefine the cane plantation label to be 1 - 24\n",
    "    new_y = [int(str(label)[1:]) for label in target]\n",
    "    \n",
    "    return np.array(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24106a94-1b9d-4a98-aecb-7939d1e9b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, labels_train = file_to_data('training_data_1718.csv')\n",
    "data_test, labels_test = file_to_data('training_data_1819.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85fa0d87-8790-4b9b-83ff-729d6e524709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 40  50  60  70  71  72  80  81  82  90 100 200]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = data_to_lv1_x_y(data_train, labels_train)\n",
    "X_test, y_test = data_to_lv1_x_y(data_test, labels_test)\n",
    "\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aea766a-5854-46df-a747-eb52c0daa627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lu_encoder = LabelEncoder()\n",
    "\n",
    "y_train = lu_encoder.fit_transform(y_train)\n",
    "y_test = lu_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c627278-5c7a-440a-95b7-7d1daf65a3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric class of y train: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "numeric class of y test: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n"
     ]
    }
   ],
   "source": [
    "print(f'numeric class of y train: {np.unique(y_train)}')\n",
    "print(f'numeric class of y test: {np.unique(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f70f9ae2-4884-41f9-970d-a6bad47c9e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train>9] = 10\n",
    "y_test[y_test > 9] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49f7d446-48bd-4277-ad00-970435d41bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numeric class of y train: [ 0  1  2  3  4  5  6  7  8  9 10]\n",
      "numeric class of y test: [ 0  1  2  3  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "print(f'numeric class of y train: {np.unique(y_train)}')\n",
    "print(f'numeric class of y test: {np.unique(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10a52ff3-b89b-4f57-8ac9-686f8788dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ee2be33-8fed-4f9f-a34b-75580d53b73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({10: 12367, 0: 118, 1: 92, 2: 85, 4: 30, 5: 30, 7: 30, 9: 30, 8: 30, 3: 26, 6: 22})\n"
     ]
    }
   ],
   "source": [
    "shape = X_train.shape\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e20c3a0-7f0c-4db5-8f0c-fb375f6346b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12860, 72)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74eb251b-9aa5-4a0c-b6a9-72cef9036db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating the random over sampler \n",
    "# ros = RandomOverSampler()\n",
    "# # resampling X, y\n",
    "# X_train, y_train = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# print(f'after oversampled-> X shape: {X_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48a31731-2feb-4dc7-b00a-3287ad43ecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add intercept to our X\n",
    "intercept = np.ones((X_train.shape[0], 1))\n",
    "X_train   = np.concatenate((intercept, X_train), axis=1)  #add intercept\n",
    "intercept = np.ones((X_test.shape[0], 1))\n",
    "X_test    = np.concatenate((intercept, X_test), axis=1)  #add intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258ae669-7f45-4d63-8101-13c83729abbd",
   "metadata": {},
   "source": [
    "## 3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0919220-fc65-453d-ad9c-39261c3a02b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, multi_class='multinomial')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23b8856-ace6-428b-beac-20870f25ff6e",
   "metadata": {},
   "source": [
    "## 4. Training Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36364092-69eb-4300-a5f3-ca6aac408408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Classification report=======\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       118\n",
      "           1       0.95      1.00      0.97        92\n",
      "           2       0.98      0.96      0.97        85\n",
      "           3       1.00      0.08      0.14        26\n",
      "           4       0.86      0.20      0.32        30\n",
      "           5       1.00      0.00      0.00        30\n",
      "           6       1.00      0.95      0.98        22\n",
      "           7       0.96      0.83      0.89        30\n",
      "           8       0.93      0.87      0.90        30\n",
      "           9       0.78      0.23      0.36        30\n",
      "          10       0.99      1.00      1.00     12367\n",
      "\n",
      "    accuracy                           0.99     12860\n",
      "   macro avg       0.95      0.65      0.68     12860\n",
      "weighted avg       0.99      0.99      0.99     12860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_train)\n",
    "print(\"=========Classification report=======\")\n",
    "print(\"Report: \", classification_report(y_train, yhat, zero_division=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96624cf-ffec-4008-aedb-9d7489483651",
   "metadata": {},
   "source": [
    "## 5. Testing Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97dd2041-f5ae-4202-8499-8e60f8493b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Classification report=======\n",
      "Report:                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       118\n",
      "           1       0.93      1.00      0.96        92\n",
      "           2       0.98      0.96      0.97        85\n",
      "           3       0.67      0.08      0.14        26\n",
      "           4       1.00      0.20      0.33        30\n",
      "           5       0.00      0.00      0.00        30\n",
      "           6       1.00      0.95      0.98        22\n",
      "           7       0.96      0.83      0.89        30\n",
      "           8       0.93      0.87      0.90        30\n",
      "           9       0.88      0.23      0.37        30\n",
      "          10       0.99      1.00      0.99      7452\n",
      "\n",
      "    accuracy                           0.98      7945\n",
      "   macro avg       0.85      0.65      0.68      7945\n",
      "weighted avg       0.98      0.98      0.98      7945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X_test)\n",
    "print(\"=========Classification report=======\")\n",
    "print(\"Report: \", classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae24c27-7db2-4c2c-bdd2-1009b80a64e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
